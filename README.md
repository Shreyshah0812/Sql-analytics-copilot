# ğŸ§  SQL + Analytics Copilot

A production-quality AI copilot that converts plain English into SQL, runs queries, auto-charts results, and explains them like a senior data analyst.

Built for **data analyst portfolio projects** â€” maps directly to real DA workflows.

---

## ğŸ“¸ What it does

1. **Connect** to a sample SQLite DB or upload your own CSV
2. **Ask** a question in plain English
3. **Get back:**
   - âœ… Generated SQL (transparent, editable)
   - âœ… Query results table (downloadable)
   - âœ… Auto chart (line, bar, scatter, KPI card)
   - âœ… Analyst-style explanation with assumptions + pitfalls
4. **Auto-fix** â€” if SQL errors, Claude rewrites and retries automatically
5. **Follow-up questions** â€” multi-turn context (ask "now break it down by country")

---

## ğŸ—ï¸ Architecture

```
User (Streamlit UI)
        â†•
    app.py  â† orchestration layer
        â†•
  utils/llm.py  â† Claude API (sql_gen â†’ sql_fix â†’ explain)
        â†•
utils/guardrails.py  â† safety validation
        â†•
  utils/db.py  â† SQLite or DuckDB (CSV) execution
        â†•
 utils/charts.py  â† auto Plotly chart selection
        â†•
utils/validators.py  â† data quality checks
```

---

## ğŸš€ Setup

### 1. Clone & install

```bash
git clone <your-repo>
cd sql-analytics-copilot
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Add your API key

```bash
cp .env.example .env
# Edit .env and add your ANTHROPIC_API_KEY
```

### 3. Run

```bash
streamlit run app.py
```

The sample DB is auto-seeded on first run. No setup needed.

---

## ğŸ’¡ Example questions to try

| Question | What it demonstrates |
|---|---|
| "Revenue trend by month" | Time series line chart |
| "Top 10 customers by total spend" | Bar chart + ranking |
| "Revenue by country" | Category aggregation |
| "Average order value" | KPI card |
| "Which genres are most popular?" | Join across tables |
| "Now break it down by year" | Follow-up / multi-turn |

---

## ğŸ›¡ï¸ Safety features

- Blocks `DROP`, `DELETE`, `UPDATE`, `INSERT`, `ALTER`, `TRUNCATE`, `PRAGMA`, `ATTACH`
- Enforces `LIMIT 1000` max to prevent runaway queries
- Auto-adds `LIMIT 100` if missing
- Rejects queries that don't start with `SELECT` or `WITH`

---

## ğŸ“ Project structure

```
sql-analytics-copilot/
  app.py                  â† Main Streamlit app
  requirements.txt
  .env.example
  db/
    sample.db             â† Auto-seeded Chinook-style DB
  prompts/
    sql_gen.txt           â† NL â†’ SQL system prompt
    sql_fix.txt           â† Error correction prompt
    sql_explain.txt       â† Result explanation prompt
  metrics/
    kpis.yaml             â† Business KPI definitions
  utils/
    db.py                 â† Schema extraction + query execution
    llm.py                â† Claude API calls
    guardrails.py         â† SQL safety validation
    charts.py             â† Auto chart selection (Plotly)
    validators.py         â† Post-query data quality checks
```

---

## ğŸ”§ Extending it

| Feature | Where to add |
|---|---|
| Connect to Postgres | `utils/db.py` â€” swap SQLite for `psycopg2` |
| Add more KPIs | `metrics/kpis.yaml` |
| Tune SQL rules | `prompts/sql_gen.txt` |
| Add more chart types | `utils/charts.py` |
| Add auth | Wrap `app.py` with `streamlit-authenticator` |

---

## âš ï¸ Limitations

- Read-only queries only (by design)
- SQL dialect: SQLite (for file DB) or DuckDB SQL (for CSV uploads)
- LLM may hallucinate if schema is very large (>50 tables) â€” use schema filtering
- Multi-file CSV joins not yet supported

---

## ğŸ“„ License

MIT
